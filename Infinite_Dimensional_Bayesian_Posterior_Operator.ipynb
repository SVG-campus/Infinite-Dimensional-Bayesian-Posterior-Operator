{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyro-ppl torch matplotlib numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sudHKdYmyv6A",
        "outputId": "9b9f4da8-ab50-4dec-ff6e-c80fb00eab6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.11/dist-packages (1.9.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (3.4.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xBABiN2EY4Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2be4cac-9e11-4868-d1d1-7ec8d5741ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting variational inference...\n",
            "Step 0: ELBO loss = 3.2720\n",
            "Step 100: ELBO loss = -16.4998\n",
            "Step 200: ELBO loss = -27.6725\n",
            "Step 300: ELBO loss = -30.7628\n",
            "Step 400: ELBO loss = -30.9810\n",
            "Step 500: ELBO loss = -30.9847\n",
            "Step 600: ELBO loss = -30.9846\n",
            "Step 700: ELBO loss = -30.9844\n",
            "Step 800: ELBO loss = -30.9847\n",
            "Step 900: ELBO loss = -30.9844\n",
            "Step 1000: ELBO loss = -30.9848\n",
            "Step 1100: ELBO loss = -30.9848\n",
            "Step 1200: ELBO loss = -30.9848\n",
            "Step 1300: ELBO loss = -30.9848\n",
            "Step 1400: ELBO loss = -30.9847\n",
            "Approximate coverage (95% band): 70.50%\n",
            "✅ Diagnostics and plots saved to 'diagnostics' folder.\n",
            "✅ Script complete. You can include these results in the proof appendix.\n"
          ]
        }
      ],
      "source": [
        "# infinite_bayesian_operator.py\n",
        "\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.contrib.gp as gp\n",
        "import pyro.distributions as dist\n",
        "import pyro.infer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "pyro.set_rng_seed(42)\n",
        "\n",
        "# --- Step 1: Generate synthetic data (representing asset returns) ---\n",
        "\n",
        "N = 50\n",
        "X = torch.linspace(0, 1, N)\n",
        "true_function = torch.sin(6 * X)  # True underlying function w0\n",
        "Y = true_function + 0.1 * torch.randn(X.size())\n",
        "\n",
        "# Save true function for diagnostic comparison\n",
        "if not os.path.exists(\"diagnostics\"):\n",
        "    os.makedirs(\"diagnostics\")\n",
        "np.savetxt(\"diagnostics/true_function.txt\", true_function.numpy())\n",
        "\n",
        "# --- Step 2: Define GP prior over function-space weights ---\n",
        "\n",
        "kernel = gp.kernels.RBF(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "gpr = gp.models.GPRegression(X.unsqueeze(-1), Y, kernel, noise=torch.tensor(0.1))\n",
        "\n",
        "# --- Step 3: Variational inference approximation to posterior using SVI ---\n",
        "\n",
        "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
        "elbo = pyro.infer.Trace_ELBO()\n",
        "svi = pyro.infer.SVI(model=gpr.model, guide=gpr.guide, optim=optimizer, loss=elbo)\n",
        "\n",
        "num_steps = 1500\n",
        "loss_trace = []\n",
        "\n",
        "print(\"Starting variational inference...\")\n",
        "for i in range(num_steps):\n",
        "    loss = svi.step()\n",
        "    loss_trace.append(loss)\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Step {i}: ELBO loss = {loss:.4f}\")\n",
        "\n",
        "# Save ELBO loss trace\n",
        "np.savetxt(\"diagnostics/loss_trace.txt\", np.array(loss_trace))\n",
        "\n",
        "# --- Step 4: Predictive posterior diagnostics ---\n",
        "\n",
        "X_test = torch.linspace(0, 1, 200).unsqueeze(-1)\n",
        "mean, cov = gpr(X_test, full_cov=True)\n",
        "std = cov.diag().sqrt()\n",
        "\n",
        "# Coverage diagnostic: Check how often true function lies within 95% credible interval\n",
        "lower = mean - 1.96 * std\n",
        "upper = mean + 1.96 * std\n",
        "\n",
        "# Interpolation of true function at test points\n",
        "true_func_test = torch.sin(6 * X_test.squeeze())\n",
        "coverage_hits = ((true_func_test >= lower) & (true_func_test <= upper)).float().mean()\n",
        "\n",
        "print(f\"Approximate coverage (95% band): {coverage_hits.item()*100:.2f}%\")\n",
        "\n",
        "# Save coverage diagnostic\n",
        "with open(\"diagnostics/coverage.txt\", \"w\") as f:\n",
        "    f.write(f\"Approximate coverage: {coverage_hits.item()*100:.2f}%\\n\")\n",
        "\n",
        "# --- Step 5: Plot posterior mean and uncertainty bands ---\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(X.numpy(), Y.numpy(), 'kx', label=\"Observations\")\n",
        "plt.plot(X_test.numpy(), mean.detach().numpy(), 'b', label=\"Posterior mean\")\n",
        "plt.fill_between(\n",
        "    X_test.squeeze().numpy(),\n",
        "    lower.detach().numpy(),\n",
        "    upper.detach().numpy(),\n",
        "    color='blue',\n",
        "    alpha=0.2,\n",
        "    label=\"95% credible band\"\n",
        ")\n",
        "plt.plot(X_test.squeeze().numpy(), true_func_test.numpy(), 'r--', label=\"True function\")\n",
        "plt.title(\"Function-space posterior with uncertainty bands\")\n",
        "plt.legend()\n",
        "plt.savefig(\"diagnostics/posterior_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# --- Step 6: Save posterior mean and std to files for further analysis ---\n",
        "\n",
        "np.savetxt(\"diagnostics/posterior_mean.txt\", mean.detach().numpy())\n",
        "np.savetxt(\"diagnostics/posterior_std.txt\", std.detach().numpy())\n",
        "\n",
        "# --- Step 7: Optional KL divergence approximation (variational diagnostic) ---\n",
        "\n",
        "final_kl = loss_trace[-1]\n",
        "with open(\"diagnostics/final_kl.txt\", \"w\") as f:\n",
        "    f.write(f\"Approximate final negative ELBO (proxy KL): {final_kl:.4f}\\n\")\n",
        "\n",
        "print(\"✅ Diagnostics and plots saved to 'diagnostics' folder.\")\n",
        "print(\"✅ Script complete. You can include these results in the proof appendix.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stress_bayesian_operator.py\n",
        "\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.contrib.gp as gp\n",
        "import pyro.infer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "pyro.set_rng_seed(42)\n",
        "\n",
        "if not os.path.exists(\"stress_diagnostics\"):\n",
        "    os.makedirs(\"stress_diagnostics\")\n",
        "\n",
        "def diagnostics(X_test, mean, std, true_func):\n",
        "    lower = mean - 1.96 * std\n",
        "    upper = mean + 1.96 * std\n",
        "    coverage = ((true_func >= lower) & (true_func <= upper)).float().mean().item() * 100\n",
        "    mse = torch.mean((mean - true_func) ** 2).item()\n",
        "    avg_std = torch.mean(std).item()\n",
        "    return coverage, mse, avg_std\n",
        "\n",
        "sample_sizes = [50, 200, 500, 1000, 2000, 3000]\n",
        "noise_type = 'student_t'\n",
        "true_function_type = 'sin'\n",
        "\n",
        "for N in sample_sizes:\n",
        "    print(f\"\\n🔬 Running stress test with N = {N} ...\")\n",
        "\n",
        "    pyro.clear_param_store()\n",
        "\n",
        "    X = torch.linspace(0, 1, N)\n",
        "\n",
        "    if true_function_type == 'sin':\n",
        "        true_function = torch.sin(6 * X)\n",
        "    elif true_function_type == 'piecewise':\n",
        "        true_function = torch.where(X < 0.5, 0.5 * torch.ones_like(X), -0.5 * torch.ones_like(X))\n",
        "    elif true_function_type == 'jump':\n",
        "        true_function = torch.sin(6 * X)\n",
        "        true_function[X > 0.7] += 1.0\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported true function type.\")\n",
        "\n",
        "    if noise_type == 'gaussian':\n",
        "        Y = true_function + 0.1 * torch.randn(X.size())\n",
        "    elif noise_type == 'student_t':\n",
        "        Y = true_function + 0.1 * torch.distributions.StudentT(df=3).sample(X.size())\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported noise type.\")\n",
        "\n",
        "    kernel = gp.kernels.RBF(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "    kernel.jitter = 1e-2  # High jitter\n",
        "\n",
        "    # ✅ FINAL: Fixed, small number of inducing points with fixed positions\n",
        "    if N <= 25:\n",
        "        num_inducing = 5\n",
        "    elif N <= 200:\n",
        "        num_inducing = 10\n",
        "    else:\n",
        "        num_inducing = 15\n",
        "    Xu = torch.linspace(0, 1, num_inducing).unsqueeze(-1)\n",
        "\n",
        "    likelihood = gp.likelihoods.Gaussian()\n",
        "    likelihood.noise = torch.tensor(0.1)\n",
        "\n",
        "    gpr = gp.models.VariationalSparseGP(X.unsqueeze(-1), Y, kernel, Xu, likelihood)\n",
        "\n",
        "    optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
        "    elbo = pyro.infer.Trace_ELBO()\n",
        "    svi = pyro.infer.SVI(model=gpr.model, guide=gpr.guide, optim=optimizer, loss=elbo)\n",
        "\n",
        "    num_steps = 1500\n",
        "    loss_trace = []\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        loss = svi.step()\n",
        "        loss_trace.append(loss)\n",
        "\n",
        "    X_test = torch.linspace(0, 1, 500).unsqueeze(-1)\n",
        "    mean, cov = gpr(X_test, full_cov=True)\n",
        "    std = cov.diag().sqrt()\n",
        "\n",
        "    true_func_test = torch.sin(6 * X_test.squeeze())\n",
        "    if true_function_type == 'piecewise':\n",
        "        true_func_test = torch.where(X_test.squeeze() < 0.5, 0.5, -0.5)\n",
        "    elif true_function_type == 'jump':\n",
        "        true_func_test = torch.sin(6 * X_test.squeeze())\n",
        "        true_func_test[X_test.squeeze() > 0.7] += 1.0\n",
        "\n",
        "    coverage, mse, avg_std = diagnostics(X_test.squeeze(), mean, std, true_func_test)\n",
        "\n",
        "    print(f\"N = {N} | Coverage: {coverage:.2f}% | MSE: {mse:.4f} | Avg Std: {avg_std:.4f}\")\n",
        "\n",
        "    np.savetxt(f\"stress_diagnostics/loss_trace_N{N}.txt\", np.array(loss_trace))\n",
        "    np.savetxt(f\"stress_diagnostics/posterior_mean_N{N}.txt\", mean.detach().numpy())\n",
        "    np.savetxt(f\"stress_diagnostics/posterior_std_N{N}.txt\", std.detach().numpy())\n",
        "\n",
        "    with open(f\"stress_diagnostics/summary_N{N}.txt\", \"w\") as f:\n",
        "        f.write(f\"Coverage: {coverage:.2f}%\\n\")\n",
        "        f.write(f\"MSE: {mse:.4f}\\n\")\n",
        "        f.write(f\"Avg posterior std: {avg_std:.4f}\\n\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(X.numpy(), Y.numpy(), 'kx', label=\"Observations\")\n",
        "    plt.plot(X_test.numpy(), mean.detach().numpy(), 'b', label=\"Posterior mean\")\n",
        "    plt.fill_between(\n",
        "        X_test.squeeze().numpy(),\n",
        "        (mean - 1.96 * std).detach().numpy(),\n",
        "        (mean + 1.96 * std).detach().numpy(),\n",
        "        color='blue',\n",
        "        alpha=0.2,\n",
        "        label=\"95% credible band\"\n",
        "    )\n",
        "    plt.plot(X_test.squeeze().numpy(), true_func_test.numpy(), 'r--', label=\"True function\")\n",
        "    plt.title(f\"Posterior (N={N})\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"stress_diagnostics/posterior_plot_N{N}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VavLKw5-ypXR",
        "outputId": "dc6a59d0-fc3c-44a4-f062-f7eb647f9ed6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔬 Running stress test with N = 50 ...\n",
            "N = 50 | Coverage: 100.00% | MSE: 0.0425 | Avg Std: 0.5403\n",
            "\n",
            "🔬 Running stress test with N = 200 ...\n",
            "N = 200 | Coverage: 100.00% | MSE: 0.0008 | Avg Std: 0.2652\n",
            "\n",
            "🔬 Running stress test with N = 500 ...\n",
            "N = 500 | Coverage: 100.00% | MSE: 0.5081 | Avg Std: 0.8856\n",
            "\n",
            "🔬 Running stress test with N = 1000 ...\n",
            "N = 1000 | Coverage: 100.00% | MSE: 0.4886 | Avg Std: 0.8790\n",
            "\n",
            "🔬 Running stress test with N = 2000 ...\n",
            "N = 2000 | Coverage: 100.00% | MSE: 0.4545 | Avg Std: 0.8434\n",
            "\n",
            "🔬 Running stress test with N = 3000 ...\n",
            "N = 3000 | Coverage: 100.00% | MSE: 0.4384 | Avg Std: 0.8387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extended_bayesian_operator_tests.py\n",
        "\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.contrib.gp as gp\n",
        "import pyro.infer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "pyro.set_rng_seed(42)\n",
        "\n",
        "if not os.path.exists(\"extended_tests\"):\n",
        "    os.makedirs(\"extended_tests\")\n",
        "\n",
        "# ========================================\n",
        "# Diagnostics\n",
        "# ========================================\n",
        "def diagnostics(X_test, mean, std, true_func):\n",
        "    lower = mean - 1.96 * std\n",
        "    upper = mean + 1.96 * std\n",
        "    coverage = ((true_func >= lower) & (true_func <= upper)).float().mean().item() * 100\n",
        "    mse = torch.mean((mean - true_func) ** 2).item()\n",
        "    avg_std = torch.mean(std).item()\n",
        "    return coverage, mse, avg_std\n",
        "\n",
        "# ========================================\n",
        "# Setup kernel and GP\n",
        "# ========================================\n",
        "def build_gp(X, Y, num_inducing, kernel_type='RBF', jitter=1e-2):\n",
        "    if kernel_type == 'RBF':\n",
        "        kernel = gp.kernels.RBF(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "    elif kernel_type == 'Matern32':\n",
        "        kernel = gp.kernels.Matern32(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported kernel type.\")\n",
        "    kernel.jitter = jitter\n",
        "\n",
        "    Xu = torch.linspace(0, 1, num_inducing).unsqueeze(-1)\n",
        "    likelihood = gp.likelihoods.Gaussian()\n",
        "    likelihood.noise = torch.tensor(0.1)\n",
        "    gpr = gp.models.VariationalSparseGP(X.unsqueeze(-1), Y, kernel, Xu, likelihood)\n",
        "    return gpr\n",
        "\n",
        "# ========================================\n",
        "# True function generator\n",
        "# ========================================\n",
        "def true_function_generator(X, type='sin', drift=0.0):\n",
        "    if type == 'sin':\n",
        "        return torch.sin(6 * X + drift)\n",
        "    elif type == 'piecewise':\n",
        "        return torch.where(X < 0.5, 0.5 * torch.ones_like(X), -0.5 * torch.ones_like(X))\n",
        "    elif type == 'jump':\n",
        "        f = torch.sin(6 * X)\n",
        "        f[X > 0.7] += 1.0\n",
        "        return f\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported true function type.\")\n",
        "\n",
        "# ========================================\n",
        "# Test configurations\n",
        "# ========================================\n",
        "sample_sizes = [50, 200, 500, 1000]\n",
        "noise_types = ['gaussian', 'student_t', 'laplace']\n",
        "kernel_types = ['RBF', 'Matern32']\n",
        "\n",
        "# ========================================\n",
        "# Run all tests\n",
        "# ========================================\n",
        "for N in sample_sizes:\n",
        "    for noise_type in noise_types:\n",
        "        for kernel_type in kernel_types:\n",
        "            print(f\"\\n🔥 Running extended test: N={N}, noise={noise_type}, kernel={kernel_type}\")\n",
        "\n",
        "            pyro.clear_param_store()\n",
        "\n",
        "            X = torch.linspace(0, 1, N)\n",
        "            true_f = true_function_generator(X, type='sin', drift=0.0)\n",
        "\n",
        "            if noise_type == 'gaussian':\n",
        "                Y = true_f + 0.1 * torch.randn(X.size())\n",
        "            elif noise_type == 'student_t':\n",
        "                Y = true_f + 0.1 * torch.distributions.StudentT(df=3).sample(X.size())\n",
        "            elif noise_type == 'laplace':\n",
        "                Y = true_f + 0.1 * torch.distributions.Laplace(0, 1).sample(X.size())\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported noise type.\")\n",
        "\n",
        "            # Inducing points\n",
        "            if N <= 100:\n",
        "                num_inducing = 5\n",
        "            else:\n",
        "                num_inducing = 10\n",
        "\n",
        "            # Build GP\n",
        "            gpr = build_gp(X, Y, num_inducing, kernel_type=kernel_type, jitter=1e-2)\n",
        "\n",
        "            optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
        "            elbo = pyro.infer.Trace_ELBO()\n",
        "            svi = pyro.infer.SVI(model=gpr.model, guide=gpr.guide, optim=optimizer, loss=elbo)\n",
        "\n",
        "            num_steps = 500\n",
        "            loss_trace = []\n",
        "            t0 = time.time()\n",
        "\n",
        "            for i in range(num_steps):\n",
        "                loss = svi.step()\n",
        "                loss_trace.append(loss)\n",
        "\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            # Evaluate\n",
        "            X_test = torch.linspace(0, 1, 500).unsqueeze(-1)\n",
        "            mean, cov = gpr(X_test, full_cov=True)\n",
        "            std = cov.diag().sqrt()\n",
        "            true_f_test = true_function_generator(X_test.squeeze(), type='sin', drift=0.0)\n",
        "\n",
        "            coverage, mse, avg_std = diagnostics(X_test.squeeze(), mean, std, true_f_test)\n",
        "\n",
        "            print(f\"✅ Coverage: {coverage:.2f}% | MSE: {mse:.4f} | Avg Std: {avg_std:.4f} | Time: {elapsed:.1f}s\")\n",
        "\n",
        "            # Save\n",
        "            label = f\"N{N}_noise{noise_type}_kernel{kernel_type}\"\n",
        "            np.savetxt(f\"extended_tests/loss_trace_{label}.txt\", np.array(loss_trace))\n",
        "            np.savetxt(f\"extended_tests/posterior_mean_{label}.txt\", mean.detach().numpy())\n",
        "            np.savetxt(f\"extended_tests/posterior_std_{label}.txt\", std.detach().numpy())\n",
        "\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(X.numpy(), Y.numpy(), 'kx', label=\"Observations\")\n",
        "            plt.plot(X_test.numpy(), mean.detach().numpy(), 'b', label=\"Posterior mean\")\n",
        "            plt.fill_between(\n",
        "                X_test.squeeze().numpy(),\n",
        "                (mean - 1.96 * std).detach().numpy(),\n",
        "                (mean + 1.96 * std).detach().numpy(),\n",
        "                color='blue',\n",
        "                alpha=0.2,\n",
        "                label=\"95% credible band\"\n",
        "            )\n",
        "            plt.plot(X_test.squeeze().numpy(), true_f_test.numpy(), 'r--', label=\"True function\")\n",
        "            plt.title(f\"N={N}, noise={noise_type}, kernel={kernel_type}\")\n",
        "            plt.legend()\n",
        "            plt.savefig(f\"extended_tests/posterior_plot_{label}.png\")\n",
        "            plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHq69BWKzxhj",
        "outputId": "f4deef33-26ad-470c-b0ff-01d49de065c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔥 Running extended test: N=50, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0023 | Avg Std: 0.0700 | Time: 5.8s\n",
            "\n",
            "🔥 Running extended test: N=50, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0036 | Avg Std: 0.0993 | Time: 5.5s\n",
            "\n",
            "🔥 Running extended test: N=50, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0029 | Avg Std: 0.1649 | Time: 5.2s\n",
            "\n",
            "🔥 Running extended test: N=50, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0035 | Avg Std: 0.1541 | Time: 5.1s\n",
            "\n",
            "🔥 Running extended test: N=50, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0023 | Avg Std: 0.1026 | Time: 5.7s\n",
            "\n",
            "🔥 Running extended test: N=50, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0019 | Avg Std: 0.1144 | Time: 5.1s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.1625 | Avg Std: 0.6968 | Time: 5.9s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0012 | Avg Std: 0.0730 | Time: 5.4s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.2202 | Avg Std: 0.7690 | Time: 6.0s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0013 | Avg Std: 0.1279 | Time: 5.4s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.2909 | Avg Std: 0.8186 | Time: 6.3s\n",
            "\n",
            "🔥 Running extended test: N=200, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0011 | Avg Std: 0.0845 | Time: 5.4s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0427 | Avg Std: 0.4732 | Time: 6.2s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0002 | Avg Std: 0.0585 | Time: 5.7s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0655 | Avg Std: 0.5407 | Time: 6.0s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0008 | Avg Std: 0.1043 | Time: 6.0s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.1133 | Avg Std: 0.6257 | Time: 5.8s\n",
            "\n",
            "🔥 Running extended test: N=500, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0004 | Avg Std: 0.0842 | Time: 5.9s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0001 | Avg Std: 0.2553 | Time: 6.0s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0002 | Avg Std: 0.0502 | Time: 6.2s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0005 | Avg Std: 0.2770 | Time: 6.2s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0003 | Avg Std: 0.1064 | Time: 6.2s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0072 | Avg Std: 0.4177 | Time: 6.0s\n",
            "\n",
            "🔥 Running extended test: N=1000, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0002 | Avg Std: 0.0699 | Time: 6.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ultimate_bayesian_operator_tests.py\n",
        "\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.contrib.gp as gp\n",
        "import pyro.infer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "\n",
        "pyro.set_rng_seed(42)\n",
        "\n",
        "if not os.path.exists(\"ultimate_tests\"):\n",
        "    os.makedirs(\"ultimate_tests\")\n",
        "\n",
        "def diagnostics(X_test, mean, std, true_func):\n",
        "    lower = mean - 1.96 * std\n",
        "    upper = mean + 1.96 * std\n",
        "    coverage = ((true_func >= lower) & (true_func <= upper)).float().mean().item() * 100\n",
        "    mse = torch.mean((mean - true_func) ** 2).item()\n",
        "    avg_std = torch.mean(std).item()\n",
        "    return coverage, mse, avg_std\n",
        "\n",
        "def build_gp(X, Y, Xu, kernel):\n",
        "    likelihood = gp.likelihoods.Gaussian()\n",
        "    likelihood.noise = torch.tensor(0.1)\n",
        "    gpr = gp.models.VariationalSparseGP(X.unsqueeze(-1), Y, kernel, Xu, likelihood)\n",
        "    return gpr\n",
        "\n",
        "def true_function_generator(X, type='sin', drift=0.0):\n",
        "    if type == 'sin':\n",
        "        return torch.sin(6 * X + drift)\n",
        "    elif type == 'piecewise':\n",
        "        return torch.where(X < 0.5, 0.5 * torch.ones_like(X), -0.5 * torch.ones_like(X))\n",
        "    elif type == 'jump':\n",
        "        f = torch.sin(6 * X)\n",
        "        f[X > 0.7] += 1.0\n",
        "        return f\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported true function type.\")\n",
        "\n",
        "def posterior_sample_trajectories(gpr, X_test, num_samples=10):\n",
        "    mean, cov = gpr(X_test, full_cov=True)\n",
        "    cov = cov + 1e-4 * torch.eye(cov.shape[0], device=cov.device)\n",
        "    mvn = torch.distributions.MultivariateNormal(mean, covariance_matrix=cov)\n",
        "    samples = []\n",
        "    for _ in range(num_samples):\n",
        "        f_samp = mvn.sample()\n",
        "        samples.append(f_samp.squeeze().detach().cpu().numpy())\n",
        "    return samples\n",
        "\n",
        "def compute_eigenvalues(kernel, Xu):\n",
        "    Kuu = kernel(Xu).contiguous().detach().cpu().numpy()\n",
        "    eigvals = np.linalg.eigvalsh(Kuu + np.eye(Kuu.shape[0]) * kernel.jitter)\n",
        "    return eigvals\n",
        "\n",
        "sample_sizes = [50, 200, 500]\n",
        "noise_types = ['gaussian', 'student_t', 'laplace']\n",
        "kernel_types = ['RBF', 'Matern32']\n",
        "\n",
        "# ====================================================\n",
        "# Run all tests\n",
        "# ====================================================\n",
        "for N in sample_sizes:\n",
        "    for noise_type in noise_types:\n",
        "        for kernel_type in kernel_types:\n",
        "            print(f\"\\n🔥 Ultimate test: N={N}, noise={noise_type}, kernel={kernel_type}\")\n",
        "\n",
        "            pyro.clear_param_store()\n",
        "\n",
        "            X = torch.linspace(0, 1, N)\n",
        "            true_f = true_function_generator(X, type='sin', drift=0.0)\n",
        "\n",
        "            if noise_type == 'gaussian':\n",
        "                Y = true_f + 0.1 * torch.randn(X.size())\n",
        "            elif noise_type == 'student_t':\n",
        "                Y = true_f + 0.1 * torch.distributions.StudentT(df=3).sample(X.size())\n",
        "            elif noise_type == 'laplace':\n",
        "                Y = true_f + 0.1 * torch.distributions.Laplace(0, 1).sample(X.size())\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported noise type.\")\n",
        "\n",
        "            # ✅ Final ultimate fix for inducing points and kernel\n",
        "            if N <= 100:\n",
        "                num_inducing = 5\n",
        "            else:\n",
        "                num_inducing = 10\n",
        "            Xu = torch.linspace(0, 1, num_inducing).unsqueeze(-1)\n",
        "\n",
        "            if kernel_type == 'RBF':\n",
        "                kernel = gp.kernels.RBF(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "            elif kernel_type == 'Matern32':\n",
        "                kernel = gp.kernels.Matern32(input_dim=1, lengthscale=torch.tensor(0.2))\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported kernel type.\")\n",
        "\n",
        "            kernel.jitter = 1e-1  # 🔥 large jitter for numerical stability\n",
        "\n",
        "            gpr = build_gp(X, Y, Xu, kernel)\n",
        "\n",
        "            optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
        "            elbo = pyro.infer.Trace_ELBO()\n",
        "            svi = pyro.infer.SVI(model=gpr.model, guide=gpr.guide, optim=optimizer, loss=elbo)\n",
        "\n",
        "            num_steps = 500\n",
        "            loss_trace = []\n",
        "            t0 = time.time()\n",
        "\n",
        "            for i in range(num_steps):\n",
        "                loss = svi.step()\n",
        "                loss_trace.append(loss)\n",
        "\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            X_test = torch.linspace(0, 1, 500).unsqueeze(-1)\n",
        "            mean, cov = gpr(X_test, full_cov=True)\n",
        "            std = cov.diag().sqrt()\n",
        "            true_f_test = true_function_generator(X_test.squeeze(), type='sin', drift=0.0)\n",
        "\n",
        "            coverage, mse, avg_std = diagnostics(X_test.squeeze(), mean, std, true_f_test)\n",
        "\n",
        "            # Posterior sample trajectories\n",
        "            samples = posterior_sample_trajectories(gpr, X_test, num_samples=10)\n",
        "\n",
        "            # Eigenvalues\n",
        "            eigvals = compute_eigenvalues(kernel, Xu)\n",
        "\n",
        "            print(f\"✅ Coverage: {coverage:.2f}% | MSE: {mse:.4f} | Avg Std: {avg_std:.4f} | Time: {elapsed:.1f}s\")\n",
        "\n",
        "            # Save everything\n",
        "            label = f\"N{N}_noise{noise_type}_kernel{kernel_type}\"\n",
        "            np.savetxt(f\"ultimate_tests/loss_trace_{label}.txt\", np.array(loss_trace))\n",
        "            np.savetxt(f\"ultimate_tests/posterior_mean_{label}.txt\", mean.detach().numpy())\n",
        "            np.savetxt(f\"ultimate_tests/posterior_std_{label}.txt\", std.detach().numpy())\n",
        "            np.savetxt(f\"ultimate_tests/eigenvalues_{label}.txt\", eigvals)\n",
        "\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(X.numpy(), Y.numpy(), 'kx', label=\"Observations\")\n",
        "            plt.plot(X_test.numpy(), mean.detach().numpy(), 'b', label=\"Posterior mean\")\n",
        "            plt.fill_between(\n",
        "                X_test.squeeze().numpy(),\n",
        "                (mean - 1.96 * std).detach().numpy(),\n",
        "                (mean + 1.96 * std).detach().numpy(),\n",
        "                color='blue',\n",
        "                alpha=0.2,\n",
        "                label=\"95% credible band\"\n",
        "            )\n",
        "            plt.plot(X_test.squeeze().numpy(), true_f_test.numpy(), 'r--', label=\"True function\")\n",
        "            for samp in samples:\n",
        "                plt.plot(X_test.squeeze().numpy(), samp[:len(X_test)], 'g', alpha=0.3)\n",
        "            plt.title(f\"N={N}, noise={noise_type}, kernel={kernel_type}\")\n",
        "            plt.legend()\n",
        "            plt.savefig(f\"ultimate_tests/posterior_plot_{label}.png\")\n",
        "            plt.close()\n",
        "\n",
        "            plt.figure(figsize=(8, 5))\n",
        "            plt.plot(np.sort(eigvals)[::-1], 'o-', label=\"Kernel eigenvalues\")\n",
        "            plt.yscale(\"log\")\n",
        "            plt.title(f\"Eigenvalue decay - {label}\")\n",
        "            plt.xlabel(\"Index\")\n",
        "            plt.ylabel(\"Eigenvalue (log scale)\")\n",
        "            plt.legend()\n",
        "            plt.savefig(f\"ultimate_tests/eigen_plot_{label}.png\")\n",
        "            plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9x3YPLIEW01",
        "outputId": "fa674689-f5a5-4c1b-dc63-cd2e95c986ef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔥 Ultimate test: N=50, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0023 | Avg Std: 0.0700 | Time: 6.6s\n",
            "\n",
            "🔥 Ultimate test: N=50, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0024 | Avg Std: 0.0925 | Time: 5.7s\n",
            "\n",
            "🔥 Ultimate test: N=50, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0009 | Avg Std: 0.1181 | Time: 8.3s\n",
            "\n",
            "🔥 Ultimate test: N=50, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0032 | Avg Std: 0.1127 | Time: 5.4s\n",
            "\n",
            "🔥 Ultimate test: N=50, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0020 | Avg Std: 0.1021 | Time: 6.0s\n",
            "\n",
            "🔥 Ultimate test: N=50, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0023 | Avg Std: 0.1251 | Time: 7.0s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0443 | Avg Std: 0.5501 | Time: 5.7s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0005 | Avg Std: 0.0678 | Time: 6.6s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.2151 | Avg Std: 0.7466 | Time: 5.8s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0013 | Avg Std: 0.1032 | Time: 7.3s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.2762 | Avg Std: 0.7717 | Time: 5.6s\n",
            "\n",
            "🔥 Ultimate test: N=200, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0008 | Avg Std: 0.0949 | Time: 6.5s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=gaussian, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0349 | Avg Std: 0.5460 | Time: 5.7s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=gaussian, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0002 | Avg Std: 0.0551 | Time: 6.6s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=student_t, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0195 | Avg Std: 0.5402 | Time: 5.8s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=student_t, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0007 | Avg Std: 0.0854 | Time: 6.6s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=laplace, kernel=RBF\n",
            "✅ Coverage: 100.00% | MSE: 0.0292 | Avg Std: 0.5054 | Time: 5.9s\n",
            "\n",
            "🔥 Ultimate test: N=500, noise=laplace, kernel=Matern32\n",
            "✅ Coverage: 100.00% | MSE: 0.0005 | Avg Std: 0.0750 | Time: 6.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iaf4z-BWF6Ru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}